<!DOCTYPE HTML>
<html lang="en">

<head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Sen He</title>

  <meta name="author" content="Sauradip Nag">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="stylesheet" type="text/css" href="style.css">
  <link rel="icon" type="image/jpeg" href="images/icon.jpeg">
</head>

<body>
  <table
    style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
    <tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr style="padding:0px">
                <td style="padding:2.5%;width:63%;vertical-align:middle">
                  <p style="text-align:center">
                    <name>Sen He (何森)</name>
                    <br>
                    <font size="3"><br />Have Fun <br /> with <br />Computer Vision and Machine Learning.</font>
                  </p>
                  <br />
                  <p align="justify">
                    <font size="3">
                      I am a Research Fellow at
                      Centre for Vision Speech and Signal Processing (CVSSP) University of Surrey, working with <a
                        href="http://personal.ee.surrey.ac.uk/Personal/T.Xiang/index.html" target="_blank">
                      <font size="3">Prof. Tao Xiang</font></a>,
                      <a
                        href="http://personal.ee.surrey.ac.uk/Personal/Y.Song/index.html" target="_blank">
                        <font size="3">Dr. Yi-Zhe Song</font></a> and <a
                        href="https://yang.ac/" target="_blank">
                      <font size="3"> Dr. Yongxin Yang</font></a>.
                    </font>
                  </p>
                  <p align="justify">
                    <font size="3">
                      Prior to that, I was a PHD student at the <a href="https://www.exeter.ac.uk"
                        target="_blank">
                        <font size="3"> University of Exeter</font>
                      </a>, supervised by <a
                        href="http://pugeault.online.fr" target="_blank">
                      <font size="3">Dr. Nicolas Pugeault</font></a>. The research in my PHD focus on visual attention in computer vision.
                    </font>
                  </p>
                  <p align="justify">
                    <font size="3">
                      I obtained my Bachelor degree at College of Telecommunications and Information Engineering at <a
                        href="https://www.njupt.edu.cn" target="_blank">
                        <font size="3">NUPT</font>
                      </a>. Then I moved to <a href="https://www.ed.ac.uk" target="_blank">
                        <font size="3">Univeisity of Edinburgh</font> 
                      </a> to pursue a MSC degree at <a href="https://www.eng.ed.ac.uk/research/institutes/idcom" target="_blank">
                          <font size="3">IDCOM</font>
                      </a>
                    </font>
                  </p>
                  <br>
                  <p style="text-align:center">
                    <a href="mailto:senhe752@gmail.com" target="_blank">
                      <font size="3">Email</font>
                    </a> &nbsp/&nbsp
                    <a href="senhe_cv.pdf" target="_blank">CV</a> &nbsp/&nbsp
                    <!-- <a href="data/JonBarron-bio.txt">Biography</a> &nbsp/&nbsp -->
                    <a href="https://scholar.google.com/citations?user=FvuBXWQAAAAJ&hl=en" target="_blank">
                      <font size="3">Google Scholar</font>
                    </a> &nbsp/&nbsp
                    <a href="https://github.com/SenHe" target="_blank">
                      <font size="3"> GitHub </font>
                    </a>
                  </p>
                </td>
                <td style="padding:2.5%;width:40%;max-width:40%">
                  <a href="images/profile.jpg" target="_blank"><img style="width:100%;max-width:100%"
                      alt="Profile Photo" src="images/sen.jpeg" class="hoverZoomLink"></a>
                </td>
              </tr>
            </tbody>
          </table>

          <!-- RESEARCH -->

          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr>
                <td style="padding:20px;width:100%;vertical-align:middle;text-align:justify">
                  <heading>
                    <font size="5">Research Interests</font>
                  </heading>
                  <p>
                    <font size="3">
                      I am broadly interested in the field of Computer Vision and Deep Learning. My current research focus on <b> Few-Shot Learning (FSL)</b> and <b> Generative Adversarial Networks (GANs) as well as It's Interesting Applications</b>, I'm also keen on attention models in computer vision.
                    </font>
                  </p>
                </td>
              </tr>
            </tbody>
          </table>


          <!-- Updates on Recent Activities  -->
          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr>
                <td
                  style="padding:20px;padding-top:5px;padding-bottom:5px;width:100%;vertical-align:middle;text-align:justify">
                  <heading>
                    <font size="5">Updates</font>
                  </heading>
                  <p>
                    <font size="3">
                      <!-- <a class="button" href="#" style="color:#FFA500"><strong style="font-size:12px">New</strong></a> -->
                      <!-- <button type="submit" class="button">Click me!</button> -->
                      <ul style="padding-inline-start:0px;list-style-type:none;">
                        <!--                         <li> <a class="button" href="#" style="color:#FFA500"><strong style="font-size:12px">New</strong></a><em style="font-size:16px;"> 1 paper on Future Frame Depth Prediction communicated to <strong style="font-size:16px">ECCV 2020</strong></em></li> -->
                        <p style="margin-block-start:0px;margin-block-end:3px"></p>
                        <li> <a class="button" href="#" style="color:#FFA500"><strong
                              style="font-size:12px">New</strong></a> <strong
                            style="font-size:15px;padding-left:5px;">05/2020 : </strong>
                          <em style="font-size:16px;"> I have moved to Guildford to join<strong style="font-size:16px"> Centre for Vision Speech and Signal Processing (CVSSP),
                              University of Surrey</strong> as a Research Fellow.
                        </li>
                      </ul>
                    </font>
                  </p>
                </td>
              </tr>
            </tbody>
          </table>

          <br>
          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr>
                <td
                  style="padding:20px;padding-top:5px;padding-bottom:5px;width:100%;vertical-align:middle;text-align:justify">
                  <heading>
                    <font size="5">Experience</font>
                  </heading>

                </td>
              </tr>
            </tbody>
          </table>

          <table style="padding:20px;padding-bottom:0px" border="0" cellpadding="0" cellspacing="4">

            <tr>
              <td valign="center" rowspan=6><img height=75 width=90 border=0 src="images/UOS_1.jpg">

            <tr>
              <td>
              <td>
              <td>
              <td>
              <td>
              <td valign="top" colspan="2"><span style="font-size: 16px;" class="h1"></b><b>University of Surrey,
                    UK</b></span>
                <br><em> Research Fellow</em><br>

                <br><em>Working with Prof. Tao Xiang and Dr. Yi-Zhe Song</em><br>
                May 2020 - Present
            </tr>
      </tr>
  </table>

  <table style="padding:20px;" border="0" cellpadding="0" cellspacing="4">

    <tr>
      <td valign="center" rowspan=6><img height=75 width=90 border=0 src="images/exeter.jpeg">

    <tr>
      <td>
      <td>
      <td>
      <td>
      <td>
      <td valign="top" colspan="2"><span style="font-size: 16px;" class="h1"></b><b>University of Exeter,
            UK</b></span>
        <br><em>PHD Student</em><br>

        <br><em>Supervised by Dr. Nicolas Pugeault</em><br>
        Nov 2016 - May 2020
    </tr>
    </tr>
  </table>
  <!-- <p></p> -->

  <table style="padding:20px;padding-top:0px;" border="0" cellpadding="0" cellspacing="4">

    <tr>
      <td valign="center" rowspan=6><img height=75 width=90 border=0 src="images/edinburgh.jpeg">

    <tr>
      <td>
      <td>
      <td>
      <td>
      <td>
      <td valign="center" colspan="2"><span style="font-size: 16px;" class="h1"></b><b>University of Edinburgh, UK</b></span>
        <br><em> Master</em><br>

        Jul 2015 - Sep 2016
  </table>
  <table style="padding:20px;padding-top:0px;" border="0" cellpadding="0" cellspacing="4">

    <tr>
      <td valign="center" rowspan=6><img height=75 width=90 border=0 src="images/nupt.jpeg">

    <tr>
      <td>
      <td>
      <td>
      <td>
      <td>
      <td valign="center" colspan="2"><span style="font-size: 16px;" class="h1"></b><b>Nanjing University of Posts and Telecommunications, China</b></span>
        <br><em>Bachelor</em><br>

        Sep 2011 - Jun 2015
  </table>

  <br>
  <!-- PUBLICATIONS -->

  <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
    <tbody>
      <tr>
        <td style="padding:20px;padding-top:5px;padding-bottom:3px;width:100%;vertical-align:middle">
          <heading>
            <font size="5">Publications</font>
          </heading>
        </td>
      </tr>
    </tbody>
  </table>

  <script>
    function myFunction(pub_name) {
      var x = document.getElementById(pub_name);
      if (x.style.display === 'none') {
        x.style.display = 'block';
      } else {
        x.style.display = 'none';
      }
    }
  </script>





  <!-- JOURNAL SECTION        -->




  <!-- CONFERENCE SECTION -->


  <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
    <tbody>

      <!-- ACCV 2020 Image Captioning- -->
      <tr onmouseout="accv_20_stop()" onmouseover="accv_20_start()">
        <td style="padding:20px;width:25%;vertical-align:middle">
          <div class="one">
            <div class="two" id='accv_20_image'><img src='images/accv_2020_imgcap_1.png'></div>
            <img src='images/accv_2020_imgcap.png'>
          </div>
          <script type="text/javascript">
            function accv_20_start() {
              document.getElementById('accv_20_image').style.opacity = "1";
            }

            function accv_20_stop() {
              document.getElementById('accv_20_image').style.opacity = "0";
            }
            accv_20_stop()
          </script>
        </td>
        <td style="padding:20px;width:75%;vertical-align:middle">
          <a href="https://arxiv.org/pdf/2004.14231.pdf" target="_blank">
            <papertitle>
              <font size="3">Image Captioning through Image Transformer
              </font>
            </papertitle>
          </a>
          <br>
          <p></p>
          <font size="3">
            <strong>
              <font size="3">Sen He</font>
            </strong>,
            <font size="3">Wentong Liao</font>,
            <font size="3">Hamed R. Tavakoli</font>,
            <font size="3">Michael Yang</font>,
            <font size="3">Bodo Rosenhahn</font>,
            <font size="3">Nicolas Pugeault</font>
            <br>
            <em>Asian Conference on Computer Vision (ACCV)</em>, 2020
            <br>
            <em>Kyoto, Japan </em>
          </font>
          <br>
          <p></p>
          <a href="https://github.com/wtliao/ImageTransformer" target="_blank">
            <font size="3">Code</font>
          </a> /
          <a href="javascript:void(0);" onclick="myFunction('accv2020_bib')">
            <font size="3">BibTex</font>
          </a>
          <div id="accv2020_bib" style="font-family:Courier;display:none;min-width:350px;">
            <font size="2">
              <br>
              @inproceedings{he2020image,<br>
              title={Image Captioning through Image Transformer},<br>
              author={He, Sen and Liao, Wentong and Tavakoli, Hamed R and Yang, Michael and Rosenhahn, Bodo and Pugeault, Nicolas},<br>
              booktitle={ACCV},<br>
              year={2020}<br>
              }<br>
            </font>
          </div>
        </td>
      </tr>



      <!-- BMVC 2020 Image Captioning- -->
      <tr onmouseout="bmvc_20_stop()" onmouseover="bmvc_20_start()">
        <td style="padding:20px;width:25%;vertical-align:middle">
          <div class="one">
            <div class="two" id='bmvc_20_image'><img src='images/bmvc_spherical_2020_1.png'></div>
            <img src='images/bmvc_2020_spherical.png'>
          </div>
          <script type="text/javascript">
            function bmvc_20_start() {
              document.getElementById('bmvc_20_image').style.opacity = "1";
            }

            function bmvc_20_stop() {
              document.getElementById('bmvc_20_image').style.opacity = "0";
            }
            bmvc_20_stop()
          </script>
        </td>
        <td style="padding:20px;width:75%;vertical-align:middle">
          <a href="https://www.bmvc2020-conference.com/assets/papers/0053.pdf" target="_blank">
            <papertitle>
              <font size="3">A Spherical Approach to Planar Semantic Segmentation
              </font>
            </papertitle>
          </a>
          <br>
          <p></p>
          <font size="3">
            <font size="3">Chao Zhang</font>
            <strong>,
              <font size="3">Sen He</font>,
            </strong>
            <font size="3">Stephan Liwicki</font>
            <br>
            <em>British Machine Vision Conference (BMVC)</em>, 2020
            <br>
            <em> UK </em>
          </font>
          <br>
          <p></p>
          <a href="javascript:void(0);" onclick="myFunction('bmvc2020_bib')">
            <font size="3">BibTex</font>
          </a>
          <div id="bmvc2020_bib" style="font-family:Courier;display:none;min-width:350px;">
            <font size="2">
              <br>
              @inproceedings{chao2020spherical,<br>
              title={A Spherical Approach to Planar Semantic Segmentation},<br>
              author={Chao Zhang and Sen, He and Stephan Liwichi},<br>
              booktitle={BMVC},<br>
              year={2020}<br>
              }<br>
            </font>
          </div>
        </td>
      </tr>


      <!-- ICCV 2019 Image Captioning- -->
      <tr onmouseout="iccv_19_stop()" onmouseover="iccv_19_start()">
        <td style="padding:20px;width:25%;vertical-align:middle">
          <div class="one">
            <div class="two" id='iccv_19_image'><img src='images/iccv_2019_1.png'></div>
            <img src='images/iccv_2019.png'>
          </div>
          <script type="text/javascript">
            function iccv_19_start() {
              document.getElementById('iccv_19_image').style.opacity = "1";
            }

            function iccv_19_stop() {
              document.getElementById('iccv_19_image').style.opacity = "0";
            }
            iccv_19_stop()
          </script>
        </td>
        <td style="padding:20px;width:75%;vertical-align:middle">
          <a href="https://openaccess.thecvf.com/content_ICCV_2019/papers/He_Human_Attention_in_Image_Captioning_Dataset_and_Analysis_ICCV_2019_paper.pdf" target="_blank">
            <papertitle>
              <font size="3">Human Attention in Image Captioning: Dataset and Analysis
              </font>
            </papertitle>
          </a>
          <br>
          <p></p>
          <font size="3">
            <strong>
              <font size="3">Sen He</font>
            </strong>,
            <font size="3">Hamed R. Tavakoli</font>,
            <font size="3">Ali Borji</font>,
            <font size="3">Nicolas Pugeault</font>
            <br>
            <em>International Conference on Computer Vision (ICCV)</em>, 2019
            <br>
            <em>Seoul, Korea </em>
          </font>
          <br>
          <p></p>
          <a href="https://github.com/SenHe/Human-Attention-in-Image-Captioning" target="_blank">
            <font size="3">Code and Data</font>
          </a> /
          <a href="javascript:void(0);" onclick="myFunction('iccv2019_bib')">
            <font size="3">BibTex</font>
          </a>
          <div id="iccv2019_bib" style="font-family:Courier;display:none;min-width:350px;">
            <font size="2">
              <br>
              @inproceedings{he2019human,<br>
              title={Human Attention in Image Captioning: Dataset and Analysis},<br>
              author={He, Sen and Tavakoli, Hamed R and Ali Borji and Pugeault, Nicolas},<br>
              booktitle={ICCV},<br>
              year={2019}<br>
              }<br>
            </font>
          </div>
        </td>
      </tr>



      <!-- CVPR 2019 Saliency- -->
      <tr onmouseout="cvpr_19_stop()" onmouseover="cvpr_19_start()">
        <td style="padding:20px;width:25%;vertical-align:middle">
          <div class="one">
            <div class="two" id='cvpr_19_image'><img src='images/cvpr_2019.png'></div>
            <img src='images/cvpr_2019_1.png'>
          </div>
          <script type="text/javascript">
            function cvpr_19_start() {
              document.getElementById('cvpr_19_image').style.opacity = "1";
            }

            function cvpr_19_stop() {
              document.getElementById('cvpr_19_image').style.opacity = "0";
            }
            cvpr_19_stop()
          </script>
        </td>
        <td style="padding:20px;width:75%;vertical-align:middle">
          <a href="https://openaccess.thecvf.com/content_CVPR_2019/papers/He_Understanding_and_Visualizing_Deep_Visual_Saliency_Models_CVPR_2019_paper.pdf" target="_blank">
            <papertitle>
              <font size="3">Understanding and Visualizing Deep Visual Saliency Models
              </font>
            </papertitle>
          </a>
          <br>
          <p></p>
          <font size="3">
            <strong>
              <font size="3">Sen He</font>
            </strong>,
            <font size="3">Hamed R. Tavakoli</font>,
            <font size="3">Ali Borji</font>,
            <font size="3">Yang Mi</font>,
            <font size="3">Nicolas Pugeault</font>
            <br>
            <em> International Conference on Computer Vision and Pattern Recognition (CVPR)</em>, 2019
            <br>
            <em>Long Beach, California, USA </em>
          </font>
          <br>
          <p></p>
          <a href="https://github.com/SenHe/uavdvsm" target="_blank">
            <font size="3">Code and Data</font>
          </a> /
          <a href="javascript:void(0);" onclick="myFunction('cvpr2019_bib')">
            <font size="3">BibTex</font>
          </a>
          <div id="cvpr2019_bib" style="font-family:Courier;display:none;min-width:350px;">
            <font size="2">
              <br>
              @inproceedings{he2019understanding,<br>
              title={Understanding and Visualizing Deep Visual Saliency Models},<br>
              author={He, Sen and Hamed R. Tavakoli and Ali Borji and Yang Mi and Pugeault, Nicolas},<br>
              booktitle={CVPR},<br>
              year={2019}<br>
              }<br>
            </font>
          </div>
        </td>
      </tr>


      <!-- ICPR 2018 steering angle- -->
      <tr onmouseout="icpr_18_stop()" onmouseover="icpr_18_start()">
        <td style="padding:20px;width:25%;vertical-align:middle">
          <div class="one">
            <div class="two" id='icpr_18_image'><img src='images/icpr_2018.png'></div>
            <img src='images/icpr_2018_1.png'>
          </div>
          <script type="text/javascript">
            function icpr_18_start() {
              document.getElementById('icpr_18_image').style.opacity = "1";
            }

            function icpr_18_stop() {
              document.getElementById('icpr_18_image').style.opacity = "0";
            }
            icpr_18_stop()
          </script>
        </td>
        <td style="padding:20px;width:75%;vertical-align:middle">
          <a href="https://arxiv.org/pdf/1803.05785.pdf" target="_blank">
            <papertitle>
              <font size="3">Aggregated Sparse Attention for Steering Angle Prediction
              </font>
            </papertitle>
          </a>
          <br>
          <p></p>
          <font size="3">
            <strong>
              <font size="3">Sen He</font>
            </strong>,
            <font size="3">Dmitry Kangin</font>,
            <font size="3">Yang Mi</font>,
            <font size="3">Nicolas Pugeault</font>
            <br>
            <em> International Conference on Pattern Recognition (ICPR)</em>, 2018
            <br>
            <em>Beijing, China </em>
          </font>
          <br>
          <p></p>
          <a href="javascript:void(0);" onclick="myFunction('icpr2018_bib')">
            <font size="3">BibTex</font>
          </a>
          <div id="icpr2018_bib" style="font-family:Courier;display:none;min-width:350px;">
            <font size="2">
              <br>
              @inproceedings{he2018aggregated,<br>
              title={Aggregated Sparse Attention for Steering Angle Prediction},<br>
              author={He, Sen and Kangin Dmitry and Yang Mi and Pugeault, Nicolas},<br>
              booktitle={ICPR},<br>
              year={2018}<br>
              }<br>
            </font>
          </div>
        </td>
      </tr>

    </tbody>
  </table>

  <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
    <tbody>
      <tr>
        <!-- <td style="padding:20px;padding-top:8px;padding-bottom:5px;width:100%;vertical-align:middle">
                  <heading>
                    <font size="4">Projects</font>
                  </heading>
                </td> -->
        <td style="padding:20px;width:100%;vertical-align:middle">
          <heading>
            <font size="5">Projects</font>
          </heading>
        </td>
      </tr>
    </tbody>
  </table>
  <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
    <tbody>

      <tr onmouseout="proj_sisr_stop()" onmouseover="proj_sisr_start()">
        <td style="padding:20px;width:25%;vertical-align:middle">
          <div class="one">
            <div class="two" id='proj_sisr_image'><img src='images/talvt_re.gif'></div>
            <img src='images/talvt_re.gif'>
          </div>
          <script type="text/javascript">
            function proj_sisr_start() {
              document.getElementById('proj_sisr_image').style.opacity = "1";
            }

            function proj_sisr_stop() {
              document.getElementById('proj_sisr_image').style.opacity = "0";
            }
            proj_sisr_stop()
          </script>
        </td>
        <td style="padding:20px;width:75%;vertical-align:middle;text-align:justify">
          <a href="https://github.com/sauradip/lightweight_saliency_detection" target="_blank">
            <papertitle>
              <font size="3">Temporal Action Localization Visualization Tool</font>
            </papertitle>
          </a>
          <br><br>
          <font size="3">
            <!-- Image super resolution is the process of increasing the resolution of a Low Resolution (LR) image by generating pixels which interpolate best between the given LR image and the required High Resolution (HR) image. The code was written using Keras (TF backend) in Python3 and comes with an easy to use interface. -->
            <!-- The task has numerous applications like in Satellite Imaging, Surveillance, Medical image processing, Biometrics, etc. -->
            Impressive progress has been reported in recent literature for action recognition. This trend motivates
            another challenging topic - temporal action localization: given a long untrimmed video, “when does a
            specific action start and end?” This problem is important
            because real applications usually involve long untrimmed videos, which can be highly unconstrained in space
            and
            time, and one video can contain multiple action instances plus background scenes or other activities.
            However, there is practically no code available to visualize
            the results and compare with the ground truth for a given video. The only thing that is available currently
            is the quantitaive results
            which is evaluated via the codes given by respective dataset. This is a visualization tool designed to
            bridge this gap and
            observe the performance of any pytorch model on Temporal Activity Localization. This has been designed in
            HTML, CSS , JS and python.

          </font>
          <br>
          <p></p>
          <a href="https://github.com/sauradip/action_localization_visualization" target="_blank">
            <font size="3">Code</font>
          </a>
          <!-- <a href="https://arxiv.org/abs/1912.03641" target="_blank">
            <font size="3">Arxiv</font>
          </a> -->
          <p></p>
        </td>

      </tr>






      <tr onmouseout="proj_sisr_stop()" onmouseover="proj_sisr_start()">
        <td style="padding:20px;width:25%;vertical-align:middle">
          <div class="one">
            <div class="two" id='proj_sisr_image'><img src='images/robot_loco_short.gif'></div>
            <img src='images/robot_loco_short.gif'>
          </div>
          <script type="text/javascript">
            function proj_sisr_start() {
              document.getElementById('proj_sisr_image').style.opacity = "1";
            }

            function proj_sisr_stop() {
              document.getElementById('proj_sisr_image').style.opacity = "0";
            }
            proj_sisr_stop()
          </script>
        </td>
        <td style="padding:20px;width:75%;vertical-align:middle;text-align:justify">
          <a href="https://github.com/sauradip/vision_based_robot_navigation" target="_blank">
            <papertitle>
              <font size="3">Computer Vision based Robot Locomotion</font>
            </papertitle>
          </a>
          <br><br>
          <font size="3">
            <!-- Image super resolution is the process of increasing the resolution of a Low Resolution (LR) image by generating pixels which interpolate best between the given LR image and the required High Resolution (HR) image. The code was written using Keras (TF backend) in Python3 and comes with an easy to use interface. -->
            <!-- The task has numerous applications like in Satellite Imaging, Surveillance, Medical image processing, Biometrics, etc. -->
            Vision-based robot navigation has long been a fundamental goal in both robotics and computer vision
            research. However, we do not require all semantic labelling of a particular environment for a robot
            to move.
            It requires only the floor part of a environment to navigate its path as we are dealing with ground
            based robots. Depth information is particularly useful in predicting how much the robot can move in
            a particular direction. Hence, the marriage between both the vision tasks provides us a free space
            map which enables the robot to move freely in a given direction.Hence, we have designed a novel
            motion control algorithm
            which enables the robot to naviagte through obstacles in its path. This is implemented in Pytorch.
          </font>
          <br>
          <p></p>
          <a href="https://github.com/sauradip/vision_based_robot_navigation" target="_blank">
            <font size="3">Code</font>
          </a>
          <!-- <a href="https://github.com/YapengTian/Single-Image-Super-Resolution" target="_blank">
                    <font size="3">Papers on Super Resolution</font>
                  </a> -->
          <p></p>
        </td>

      </tr>

      <tr onmouseout="proj_sisr_stop()" onmouseover="proj_sisr_start()">
        <td style="padding:20px;width:25%;vertical-align:middle">
          <div class="one">
            <div class="two" id='proj_sisr_image'><img src='images/robot.gif'></div>
            <img src='images/robot.gif'>
          </div>
          <script type="text/javascript">
            function proj_sisr_start() {
              document.getElementById('proj_sisr_image').style.opacity = "1";
            }

            function proj_sisr_stop() {
              document.getElementById('proj_sisr_image').style.opacity = "0";
            }
            proj_sisr_stop()
          </script>
        </td>
        <td style="padding:20px;width:75%;vertical-align:middle;text-align:justify">
          <a href="https://github.com/sauradip/autonomous_robot_locomotion" target="_blank">
            <papertitle>
              <font size="3">Autonomous Robot Locomotion in prespecified path</font>
            </papertitle>
          </a>
          <br><br>
          <font size="3">
            <!-- Image super resolution is the process of increasing the resolution of a Low Resolution (LR) image by generating pixels which interpolate best between the given LR image and the required High Resolution (HR) image. The code was written using Keras (TF backend) in Python3 and comes with an easy to use interface. -->
            <!-- The task has numerous applications like in Satellite Imaging, Surveillance, Medical image processing, Biometrics, etc. -->
            Robotics have helped humans greatly in achieving everyday tasks. Robots are designed to work in any
            environment and perform task on behalf of humans. They operate under real-world and real-time
            constraints where sensors and effectors with specific physical characteristics have to be
            controlled. In many cases, those robots are controlled manually to move from one destination to
            another. An Unmanned Ground Vehicle (UGV) is a vehicle that operates while in contact with the
            ground and without an onboard human presence. We have used
            one of such robots to demonstrate the custom path which user can choose. Currently we have
            implemented 2 such custom paths. This has been implemented in Python and ROS.
          </font>
          <br>
          <p></p>
          <a href="https://github.com/sauradip/autonomous_robot_locomotion" target="_blank">
            <font size="3">Code</font>
          </a>
          <!-- <a href="https://github.com/YapengTian/Single-Image-Super-Resolution" target="_blank">
                    <font size="3">Papers on Super Resolution</font>
                  </a> -->
          <p></p>
        </td>

      </tr>

      <tr onmouseout="proj_sisr_stop()" onmouseover="proj_sisr_start()">
        <td style="padding:20px;width:25%;vertical-align:middle">
          <div class="one">
            <div class="two" id='proj_sisr_image'><img src='images/proj_5_re.gif'></div>
            <img src='images/robot.gif'>
          </div>
          <script type="text/javascript">
            function proj_sisr_start() {
              document.getElementById('proj_sisr_image').style.opacity = "1";
            }

            function proj_sisr_stop() {
              document.getElementById('proj_sisr_image').style.opacity = "0";
            }
            proj_sisr_stop()
          </script>
        </td>
        <td style="padding:20px;width:75%;vertical-align:middle;text-align:justify">
          <a href="https://github.com/sauradip/lightweight_saliency_detection" target="_blank">
            <papertitle>
              <font size="3">Light-weight Salient Object Detection</font>
            </papertitle>
          </a>
          <br><br>
          <font size="3">
            <!-- Image super resolution is the process of increasing the resolution of a Low Resolution (LR) image by generating pixels which interpolate best between the given LR image and the required High Resolution (HR) image. The code was written using Keras (TF backend) in Python3 and comes with an easy to use interface. -->
            <!-- The task has numerous applications like in Satellite Imaging, Surveillance, Medical image processing, Biometrics, etc. -->
            Salient object detection is a prevalent computer vision task that has applications ranging from abnormality
            detection to abnormality processing. Context modelling is an important criterion in the domain of saliency
            detection. A global context helps in determining the salient object in a given image by contrasting away
            other objects in the global view of the scene. However, the local context features detects the boundaries of
            the salient object with higher accuracy in a given region. To incorporate the best of both worlds, our
            proposed SaLite model uses both global and local contextual features. It is an encoder-decoder based
            architecture in which the encoder uses a lightweight SqueezeNet and decoder is modelled using convolution
            layers. This has been implemented in PyTorch.

          </font>
          <br>
          <p></p>
          <a href="https://github.com/sauradip/lightweight_saliency_detection" target="_blank">
            <font size="3">Code</font>
          </a> /
          <a href="https://arxiv.org/abs/1912.03641" target="_blank">
            <font size="3">Arxiv</font>
          </a>
          <p></p>
        </td>

      </tr>



      <tr onmouseout="proj_sisr_stop()" onmouseover="proj_sisr_start()">
        <td style="padding:20px;width:25%;vertical-align:middle">
          <div class="one">
            <div class="two" id='proj_sisr_image'><img src='images/proj_3.gif'></div>
            <img src='images/robot.gif'>
          </div>
          <script type="text/javascript">
            function proj_sisr_start() {
              document.getElementById('proj_sisr_image').style.opacity = "1";
            }

            function proj_sisr_stop() {
              document.getElementById('proj_sisr_image').style.opacity = "0";
            }
            proj_sisr_stop()
          </script>
        </td>
        <td style="padding:20px;width:75%;vertical-align:middle;text-align:justify">
          <a href="https://github.com/sauradip/Boundary-Growing-in-Python" target="_blank">
            <papertitle>
              <font size="3">Boundary Growing Algorithm for Recovery of Torso from Corrupt Face</font>
            </papertitle>
          </a>
          <br><br>
          <font size="3">
            <!-- Image super resolution is the process of increasing the resolution of a Low Resolution (LR) image by generating pixels which interpolate best between the given LR image and the required High Resolution (HR) image. The code was written using Keras (TF backend) in Python3 and comes with an easy to use interface. -->
            <!-- The task has numerous applications like in Satellite Imaging, Surveillance, Medical image processing, Biometrics, etc. -->
            Automatic face detection has been intensively studied for human related recognition systems.
            However, there has been a very little work in recovering face from a corrupted face image. We have
            designed a boundary growing algorithm where we incrementally grew the boundary of the corrupted face
            image and passed into HAAR cascade classifier to get confidence score. We kept on doing until we
            reach the maximum confidence. After that we used tailor measurements to recover the torso part of
            the human. This has been implemented using OpenCV and Python.

          </font>
          <br>
          <p></p>
          <a href="https://github.com/sauradip/Boundary-Growing-in-Python" target="_blank">
            <font size="3">Code</font>
          </a>
          <!-- <a href="https://github.com/YapengTian/Single-Image-Super-Resolution" target="_blank">
                    <font size="3">Papers on Super Resolution</font>
                  </a> -->
          <p></p>
        </td>

      </tr>


      <tr onmouseout="proj_sisr_stop()" onmouseover="proj_sisr_start()">
        <td style="padding:20px;width:25%;vertical-align:middle">
          <div class="one">
            <div class="two" id='proj_sisr_image'><img src='images/proj_4.gif'></div>
            <img src='images/proj_4.gif'>
          </div>
          <script type="text/javascript">
            function proj_sisr_start() {
              document.getElementById('proj_sisr_image').style.opacity = "1";
            }

            function proj_sisr_stop() {
              document.getElementById('proj_sisr_image').style.opacity = "0";
            }
            proj_sisr_stop()
          </script>
        </td>
        <td style="padding:20px;width:75%;vertical-align:middle;text-align:justify">
          <a href="https://github.com/sauradip/BaseLine-Remover" target="_blank">
            <papertitle>
              <font size="3">BaseLine Remover from Doument Images</font>
            </papertitle>
          </a>
          <br><br>
          <font size="3">
            <!-- Image super resolution is the process of increasing the resolution of a Low Resolution (LR) image by generating pixels which interpolate best between the given LR image and the required High Resolution (HR) image. The code was written using Keras (TF backend) in Python3 and comes with an easy to use interface. -->
            <!-- The task has numerous applications like in Satellite Imaging, Surveillance, Medical image processing, Biometrics, etc. -->
            This a small Matlab Implementation for Removal of Base Line from document using Edge Directional
            Kernel stated in paper " Edge enhancement algorithm for low-dose X-ray fluoroscopic imaging " by Lee
            et al. Here Baselines are Removed using Edge Directional Kernel . BaseLine Removal is an important
            topic in Document Image Analysis . In this paper Lee et al proposed removal of Noise from XRAY
            Images using Edge Directional Kernel and High Pass Filter but since our Noise is only Baseline we
            used a clever trick to implement only the Edge Directional Kernel and the reuslts are quite neat.
            This method works well for Half Page Document and Cropped Line Images , however if full page images
            are preprocessed then it may work pretty well.

          </font>
          <br>
          <p></p>
          <a href="https://github.com/sauradip/BaseLine-Remover" target="_blank">
            <font size="3">Code</font>
          </a> /
          <a href="https://github.com/YapengTian/Single-Image-Super-Resolution" target="_blank">
            <font size="3">Paper</font>
          </a>
          <p></p>
        </td>

      </tr>
    </tbody>
  </table>




  <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
    <tbody>
      <tr>
        <td style="padding:20px;width:100%;vertical-align:middle">
          <heading>
            <font size="5">Past Collaborators</font>
          </heading>
        </td>
      </tr>
      <tr>
        <td style="padding:0px;width:75%;vertical-align:middle">
          <!-- Projects -->

          <div class="wrapper">

            <img src="images/Umapada_Pal.jpg" class="image--cover">

            <img src="images/shivakumara.jpeg" alt="" class="image--cover" />

            <img src="images/raghavendra.jpg" alt="" class="image--cover" />

            <img src="images/Michael-Blumenstein.jpg" alt="" class="image--cover" />
          </div>
      </tr>
      <tr>
        <td style="padding:0px;width:75%;vertical-align:middle">
          <!-- Projects -->
          <!-- <div class="wrapper">

        <span style="padding-left:30px;padding-right:30px;">Umapada Pal</span>
        <span style="padding-left:30px;padding-right:30px;"></span>
        <span style="padding-left:30px;padding-right:30px;">Palaiahnakote Shivakumara</span>
        <span style="padding-left:30px;padding-right:30px;"></span>
        <span style="padding-left:30px;padding-right:30px;">Raghavendra Ramachandra</span>
        <span style="padding-left:30px;padding-right:30px;"></span>
        <span style="padding-left:30px;padding-right:30px;">Michael Blumenstein</span>

      </div> -->
          <div class="demo" style="padding:5px;">
            <span class="collab"><a style="font-size:16px"
                href="https://scholar.google.co.in/citations?user=2_z_CogAAAAJ&hl=en">Umapada Pal</a></span>
            <span class="collab" style="padding-left:35px"><a style="font-size:16px"
                href="https://scholar.google.co.in/citations?user=XfpbOc4AAAAJ&hl=en">P Shivakumara</a></span>
            <span class="collab"><a style="font-size:16px"
                href="https://scholar.google.co.in/citations?user=OIYIrmIAAAAJ&hl=en">R Ramachandra</a></span>
            <span class="collab"><a style="font-size:16px"
                href="https://scholar.google.co.in/citations?user=4m2G-H8AAAAJ&hl=en">Michael
                Blumenstein</a></span>
          </div>
          <div class="wrapper">

            <img src="images/TongLu.jpg" class="image--cover">

            <img src="images/parthapratim.jpg" alt="" class="image--cover" />

            <img src="images/mohan_kankanhalli.jpg" alt="" class="image--cover" />

            <img src="images/kd_sir_re.jpg" alt="" class="image--cover" />

          </div>
          <!-- <div class="wrapper">

        <span style="padding-left:30px;padding-right:30px;">Umapada_Pal</span>
        <span style="padding-left:30px;padding-right:30px;"></span>
        <span style="padding-left:30px;padding-right:30px;">Umapada_Pal</span>
        <span style="padding-left:30px;padding-right:30px;"></span>
        <span style="padding-left:30px;padding-right:30px;">Umapada_Pal</span>
        <span style="padding-left:30px;padding-right:30px;"></span>
        <span style="padding-left:30px;padding-right:30px;">Umapada_Pal</span>

      </div> -->
          <div class="demo">
            <span class="collab" style="padding-left:30px"><a style="font-size:16px"
                href="https://cs.nju.edu.cn/_upload/tpl/00/cd/205/template205/Publications.html">Lu
                Tong</a></span>
            <span class="collab" style="padding-left:32px"><a style="font-size:16px"
                href="https://scholar.google.co.in/citations?user=moDpyKkAAAAJ&hl=en">Partha Roy</a></span>
            <span class="collab" style="padding-left:-10px;"><a style="font-size:16px"
                href="https://scholar.google.com/citations?user=6Lx_eowAAAAJ&hl=th">M Kankanhalli</a></span>
            <span class="collab"><a style="font-size:16px"
                href="https://scholar.google.co.in/citations?user=63DEdC0AAAAJ&hl=en">Kousik Dasgupta</a></span>
          </div>
      </tr>
      <!--  -->
    </tbody>
  </table>
  <!-- Footer - Template Credits -->
  <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
    <tbody>
      <tr>
        <td style="padding:0px">
          <br>
          <p style="text-align:center;font-size:medium;">
            Visitor Map
            <!--                     <a href="https://jonbarron.info/" target="_blank">Dr. Jon Barron</a> -->
          </p>
        </td>
      </tr>
    </tbody>
  </table>

  <center>
    <script type='text/javascript' id='clustrmaps'
      src='//cdn.clustrmaps.com/map_v2.js?cl=ffffff&w=400&t=n&d=NLN3vt4IdIZciRC65gs2Q4eyOFL2xjRooRB98TlWaI0&co=118fe8'></script>
  </center>



  </td>
  </tr>
  </table>
  <br>
  <table align=center width=900px>
    <tr>
      <td align=center width=900px>
        <center><img src="./images/website_logo.png" height="90x" width="800x"></img><br></center>

      </td>
    </tr>
    <br>
  </table>
  <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
    <tbody>
      <tr>
        <td style="padding:0px">
          <br>

          <p style="text-align:center;font-size:small;">
            <!--             Template credits :
            <a href="https://jonbarron.info/" target="_blank">Dr. Jon Barron</a>  -->
            Copyright © Sauradip Nag. Last updated Sep 2020 | Template provided by <a href="https://jonbarron.info/"
              target="_blank">Dr. Jon Barron</a>
          </p>
        </td>
      </tr>
    </tbody>
  </table>
</body>

</html>
